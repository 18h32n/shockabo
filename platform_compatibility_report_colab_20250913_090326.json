{
  "platform": "colab",
  "timestamp": "2025-09-13T09:03:26.087406",
  "system_info": {
    "platform": "colab",
    "python_version": "3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]",
    "torch_version": "2.8.0+cpu",
    "cuda_available": false,
    "cuda_version": null,
    "gpu_count": 0,
    "gpu_names": [],
    "total_memory_gb": 31.927120208740234,
    "available_memory_gb": 7.456737518310547,
    "cpu_count": 12,
    "os_info": "nt Windows"
  },
  "platform_config": {
    "platform": {
      "name": "colab",
      "gpu_hours_limit": 12,
      "memory_limit_gb": 16,
      "has_persistent_storage": false
    },
    "paths": {
      "data_dir": "/content/data",
      "working_dir": "/content",
      "cache_dir": "/content/cache",
      "logs_dir": "/content/logs",
      "models_dir": "/content/models"
    },
    "database": {
      "url": "sqlite:////content/arc_prize.db"
    },
    "cache": {
      "directory": "/content/cache",
      "size_limit": "1GB"
    },
    "logging": {
      "level": "INFO",
      "file": "/content/logs/arc_prize.log"
    },
    "model": {
      "device": "cuda",
      "batch_size": 16,
      "use_fp16": true,
      "max_length": 1024
    },
    "training": {
      "batch_size": 8,
      "gradient_accumulation_steps": 2,
      "use_gpu": true
    },
    "inference": {
      "batch_size": 16,
      "use_gpu": true
    },
    "resources": {
      "max_memory_gb": 12,
      "max_concurrent_tasks": 2,
      "gpu_memory_fraction": 0.8
    },
    "features": {
      "hot_reload": false,
      "experiment_tracking": true,
      "ttt_training": false,
      "program_synthesis": true
    },
    "colab": {
      "drive_mount": "/content/drive",
      "mount_drive": false,
      "use_gpu": true,
      "use_tpu": false
    },
    "optimizations": {
      "auto_restart_on_memory_error": true,
      "clear_cache_frequently": true,
      "offload_unused_models": true
    }
  },
  "summary": {
    "total_tests": 7,
    "passed_tests": 6,
    "failed_tests": 1,
    "success_rate": 0.8571428571428571,
    "total_duration_seconds": 15.346644878387451,
    "total_memory_usage_mb": 576.4765625,
    "total_gpu_memory_mb": 0.0
  },
  "test_results": [
    {
      "test_name": "Configuration Loading",
      "platform": "colab",
      "success": true,
      "duration_seconds": 0.08021259307861328,
      "memory_usage_mb": 57.77734375,
      "gpu_memory_mb": 0.0,
      "error_message": null,
      "warnings": [],
      "metadata": {
        "config_loaded": true,
        "platform_name": "kaggle",
        "memory_limit": 32,
        "gpu_hours_limit": 30,
        "has_persistent_storage": true,
        "model_device": "cpu",
        "batch_size": 16,
        "max_memory_gb": 32
      }
    },
    {
      "test_name": "TTT Adapter Initialization",
      "platform": "colab",
      "success": true,
      "duration_seconds": 14.037605285644531,
      "memory_usage_mb": 495.76171875,
      "gpu_memory_mb": 0.0,
      "error_message": null,
      "warnings": [],
      "metadata": {
        "adapter_initialized": true,
        "device": "cpu",
        "model_name": "meta-llama/Llama-3.2-1B",
        "lora_rank": 32,
        "batch_size": 1,
        "memory_limit_mb": 10240,
        "quantization": true,
        "mixed_precision": true
      }
    },
    {
      "test_name": "Memory Constraints",
      "platform": "colab",
      "success": false,
      "duration_seconds": 0.14858245849609375,
      "memory_usage_mb": 113.265625,
      "gpu_memory_mb": 0.0,
      "error_message": "Memory usage (25.04GB) exceeds platform limit (12GB)",
      "warnings": [],
      "metadata": {}
    },
    {
      "test_name": "Data Loading",
      "platform": "colab",
      "success": true,
      "duration_seconds": 0.04430556297302246,
      "memory_usage_mb": -36.8984375,
      "gpu_memory_mb": 0.0,
      "error_message": null,
      "warnings": [],
      "metadata": {
        "training_tasks_count": 1,
        "sample_task_id": "test_task_001",
        "sample_task_loaded": true,
        "data_dir": "/content/data",
        "fallback_used": true
      }
    },
    {
      "test_name": "Model Loading and Inference",
      "platform": "colab",
      "success": true,
      "duration_seconds": 0.9216697216033936,
      "memory_usage_mb": -110.72265625,
      "gpu_memory_mb": 0.0,
      "error_message": null,
      "warnings": [],
      "metadata": {
        "adapter_initialized": true,
        "adaptation_successful": false,
        "solution_generated": true,
        "confidence_score": 0.0,
        "strategy_used": "StrategyType.TEST_TIME_TRAINING",
        "resource_usage": {
          "cpu_seconds": 0.398719,
          "memory_mb": 384.8125,
          "gpu_memory_mb": 0.0
        }
      }
    },
    {
      "test_name": "Checkpoint Management",
      "platform": "colab",
      "success": true,
      "duration_seconds": 0.059783935546875,
      "memory_usage_mb": 64.484375,
      "gpu_memory_mb": 0.0,
      "error_message": null,
      "warnings": [],
      "metadata": {
        "models_dir": "\\content\\models",
        "checkpoint_dir": "\\content\\models\\test_checkpoints",
        "working_dir": "\\content",
        "checkpoint_save": "success",
        "checkpoint_load": "success",
        "data_integrity": true,
        "disk_space": {
          "total_gb": 929.6328086853027,
          "used_gb": 562.809627532959,
          "free_gb": 366.82318115234375
        }
      }
    },
    {
      "test_name": "GPU Configurations",
      "platform": "colab",
      "success": true,
      "duration_seconds": 0.054485321044921875,
      "memory_usage_mb": -7.19140625,
      "gpu_memory_mb": 0.0,
      "error_message": null,
      "warnings": [],
      "metadata": {
        "cuda_available": false,
        "gpu_count": 0,
        "cpu_fallback": "required"
      }
    }
  ],
  "recommendations": [
    "Failed tests detected - see individual test results for details",
    "For Colab: Use smaller batch sizes and enable gradient checkpointing",
    "For Colab: Consider using quantization to reduce memory usage",
    "For Colab: Ensure GPU runtime is enabled",
    "No GPU detected - performance will be significantly reduced"
  ]
}