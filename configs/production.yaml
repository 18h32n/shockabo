# Production Configuration
# Configuration for production deployment

app:
  name: "arc-prize-2025"
  version: "0.1.0"
  debug: false
  environment: "production"

api:
  host: "0.0.0.0"
  port: 8000
  reload: false
  workers: 4  # Multiple workers for production

websocket:
  host: "0.0.0.0"
  port: 8001
  cors_allowed_origins:
    - "https://yourdomain.com"

database:
  url: "sqlite:///./data/arc_prize.db"
  pool_size: 20
  max_overflow: 40
  echo: false  # Disable SQL logging in production

cache:
  type: "diskcache"
  directory: "./data/cache"
  size_limit: "5GB"
  default_ttl: 7200

logging:
  level: "INFO"
  format: "json"
  file: "./logs/arc_prize.log"
  rotation: "daily"
  retention: 30  # Keep logs for 30 days

model:
  name: "llama-3-8b"
  device: "cuda"
  quantization: true
  max_length: 2048
  batch_size: 32

training:
  epochs: 20
  learning_rate: 5e-5
  batch_size: 16
  gradient_accumulation_steps: 1

inference:
  batch_size: 32
  max_tokens: 512
  temperature: 0.5  # More conservative in production
  top_p: 0.8

monitoring:
  metrics_enabled: true
  metrics_port: 9090
  profiling_enabled: false

security:
  rate_limit:
    requests_per_minute: 100
    burst_size: 200

resources:
  max_memory_gb: 16
  max_concurrent_tasks: 8
  max_processing_time: 600  # Longer timeout for production

features:
  hot_reload: false
  experiment_tracking: true
  ttt_training: true
  program_synthesis: true