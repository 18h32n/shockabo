{
  "test_timestamp": "2025-09-13T22:37:26.556734",
  "test_description": "QLoRA 8B Llama-3 model loading validation",
  "tests": {
    "quantization_libraries": {
      "torch_available": true,
      "transformers_available": true,
      "bitsandbytes_available": false,
      "accelerate_available": true,
      "cuda_available": false,
      "versions": {
        "torch": "2.8.0+cpu",
        "transformers": "4.55.0",
        "accelerate": "1.10.1"
      },
      "errors": [
        "BitsAndBytes not available: No module named 'bitsandbytes'"
      ],
      "bnb_config_available": true
    },
    "gpu_memory": {
      "gpu_info": {
        "gpu_available": false,
        "gpu_count": 0,
        "gpu_memory_total_mb": 0,
        "gpu_memory_available_mb": 0,
        "gpu_names": []
      },
      "model_validation": {
        "platform": "kaggle",
        "gpu_available": false,
        "gpu_memory_total_mb": 0,
        "gpu_memory_available_mb": 0,
        "meets_minimum": false,
        "meets_recommended": false,
        "meets_optimal": false,
        "memory_level": "insufficient",
        "recommendations": [
          "No GPU available, CPU-only mode will be very slow"
        ]
      }
    },
    "qlora_config": {
      "config_creation": "success",
      "default_config": {
        "load_in_4bit": true,
        "load_in_8bit": false,
        "bnb_4bit_quant_type": "nf4",
        "bnb_4bit_use_double_quant": true,
        "llm_int8_threshold": 6.0,
        "llm_int8_has_fp16_weight": false,
        "bnb_4bit_compute_dtype": "torch.float16"
      },
      "bnb_config_available": false,
      "optimal_configs": {
        "6GB": {
          "load_in_4bit": true,
          "quant_type": "nf4",
          "compute_dtype": "float16"
        },
        "12GB": {
          "load_in_4bit": true,
          "quant_type": "nf4",
          "compute_dtype": "float16"
        },
        "24GB": {
          "load_in_4bit": true,
          "quant_type": "nf4",
          "compute_dtype": "float16"
        }
      },
      "predefined_configs": [
        "optimal",
        "memory_efficient",
        "fallback_8bit"
      ]
    },
    "memory_estimation": {
      "model_params": 8000000000,
      "quantization_estimates": {
        "4bit": {
          "total_mb": 4577.63671875,
          "total_gb": 4.470348358154297,
          "memory_saved_gb": 11.175870895385742,
          "compression_ratio": 4.0
        },
        "8bit": {
          "total_mb": 9155.2734375,
          "total_gb": 8.940696716308594,
          "memory_saved_gb": 7.450580596923828,
          "compression_ratio": 2.0
        },
        "16bit": {
          "total_mb": 18310.546875,
          "total_gb": 17.881393432617188,
          "memory_saved_gb": 0.0,
          "compression_ratio": 1.0
        }
      },
      "qlora_estimate": {
        "base_model_mb": 3814.697265625,
        "lora_adapters_mb": 64.0,
        "overhead_mb": 775.7394531250001,
        "total_estimated_mb": 4654.43671875,
        "total_estimated_gb": 4.545348358154297,
        "quantization_savings_mb": 11444.091796875
      }
    },
    "ttt_config": {
      "config_loaded": true,
      "model_name": "meta-llama/Llama-3-8B",
      "lora_rank": 64,
      "memory_limit_mb": 24576,
      "load_in_4bit": true,
      "bnb_4bit_quant_type": "nf4",
      "use_flash_attention": true,
      "quantization_config": {
        "load_in_4bit": true,
        "bnb_4bit_quant_type": "nf4",
        "bnb_4bit_compute_dtype": "float16",
        "bnb_4bit_use_double_quant": true
      }
    },
    "lora_adapter": {
      "lora_config": {
        "rank": 64,
        "alpha": 16,
        "scaling": 0.25,
        "target_modules": [
          "q_proj",
          "v_proj",
          "k_proj",
          "o_proj",
          "gate_proj",
          "up_proj",
          "down_proj",
          "c_attn",
          "c_proj"
        ],
        "use_quantization": true,
        "quantization_config": {
          "load_in_4bit": true,
          "bnb_4bit_quant_type": "nf4",
          "bnb_4bit_compute_dtype": "float16",
          "bnb_4bit_use_double_quant": true
        }
      },
      "qlora_config": {
        "load_in_4bit": true,
        "bnb_4bit_quant_type": "nf4",
        "bnb_4bit_compute_dtype": "torch.float16",
        "bnb_4bit_use_double_quant": true
      }
    },
    "model_loading_simulation": {
      "simulation_results": {
        "optimal": {
          "model_name": "meta-llama/Llama-3-8B",
          "estimated_size": "8B",
          "estimated_params": 8000000000,
          "quantization_bits": 4,
          "estimated_memory_mb": 4577.63671875,
          "available_memory_mb": 24576,
          "memory_sufficient": true,
          "memory_utilization": 0.1862645149230957,
          "recommendations": [
            "Memory usage is optimal (<80%)."
          ]
        },
        "memory_efficient": {
          "model_name": "meta-llama/Llama-3-8B",
          "estimated_size": "8B",
          "estimated_params": 8000000000,
          "quantization_bits": 4,
          "estimated_memory_mb": 4577.63671875,
          "available_memory_mb": 24576,
          "memory_sufficient": true,
          "memory_utilization": 0.1862645149230957,
          "recommendations": [
            "Memory usage is optimal (<80%)."
          ]
        },
        "fallback_8bit": {
          "model_name": "meta-llama/Llama-3-8B",
          "estimated_size": "8B",
          "estimated_params": 8000000000,
          "quantization_bits": 8,
          "estimated_memory_mb": 9155.2734375,
          "available_memory_mb": 24576,
          "memory_sufficient": true,
          "memory_utilization": 0.3725290298461914,
          "recommendations": [
            "Memory usage is optimal (<80%)."
          ]
        }
      },
      "available_memory_mb": 24576,
      "available_memory_gb": 24.0
    }
  },
  "test_duration_seconds": 24.920082569122314,
  "summary": {
    "total_tests": 7,
    "successful_tests": 7,
    "failed_tests": 0,
    "success_rate": 1.0,
    "overall_status": "PASS"
  },
  "story_1_5_task_1_validation": {
    "qlora_support": true,
    "8b_model_config": true,
    "memory_within_24gb": false,
    "nf4_quantization": false,
    "rank_64_lora": true
  }
}